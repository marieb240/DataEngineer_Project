# ğŸ“Š DataEngineer_Project

ESIEE 2026 â€“ Projet Data Engineering
Marie BouÃ«tel & Ghita Bensaleh

## 1ï¸âƒ£ Introduction
Dans le cadre de lâ€™unitÃ© de Data Engineering, nous avons dÃ©veloppÃ© une application web permettant de collecter, stocker et visualiser des statistiques YouTube Ã  partir de donnÃ©es scrapÃ©es.

Lâ€™objectif du projet est de mettre en pratique :
- le web scraping
- le stockage en base de donnÃ©es
- le dÃ©veloppement dâ€™une application web en Python
- la conteneurisation avec Docker
- la rÃ©daction dâ€™une documentation technique et fonctionnelle

Notre application permet de consulter diffÃ©rentes statistiques du Top 100 des YouTubeurs mondiaux, notamment :
- ğŸ“ˆ Position (rank)
- ğŸ¥ Nombre de vidÃ©os
- ğŸ‘¥ Nombre dâ€™abonnÃ©s
- ğŸ‘ Nombre total de vues

Les donnÃ©es sont rÃ©cupÃ©rÃ©es depuis VidIQ, stockÃ©es dans MongoDB, puis affichÃ©es via une application web dÃ©veloppÃ©e avec Flask.

## 2ï¸âƒ£ Description du projet
Ce dÃ©pÃ´t contient :
- ğŸ–¥ï¸ Une application web Flask dans `app/`
- ğŸ•·ï¸ Des scrapers dans `scrapers/` (VidIQ & YouTube)
- ğŸ—„ï¸ Une base de donnÃ©es MongoDB
- ğŸ³ Des fichiers Docker pour exÃ©cution en conteneur
- ğŸŒ± Un script `seed_db.py` pour initialiser la base de donnÃ©es
- ğŸ§ª Un script `test_scraper.py` pour tester les scrapers

## 4ï¸âƒ£ Architecture du projet
Le fonctionnement gÃ©nÃ©ral est le suivant :
1. Les scrapers rÃ©cupÃ¨rent les donnÃ©es depuis VidIQ.
2. Les donnÃ©es sont nettoyÃ©es et structurÃ©es.
3. Elles sont stockÃ©es dans MongoDB.
4. Lâ€™application Flask interroge la base.
5. Les statistiques sont affichÃ©es dans lâ€™interface web.

## 5ï¸âƒ£ Structure du projet
```
DataEngineer_Project/
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ entrypoint.sh
â”œâ”€â”€ seed_db.py
â”œâ”€â”€ test_scraper.py
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ templates/
â”‚
â””â”€â”€ scrapers/
    â”œâ”€â”€ vidiq_parser.py
    â””â”€â”€ video_scraper.py
```

## 6ï¸âƒ£ Technologies utilisÃ©es
### Backend
- flask==2.3.0 â€” Framework web
- gunicorn==21.2.0 â€” Serveur WSGI
- jinja2==3.1.2 â€” Templates HTML
- werkzeug==2.3.0

### Scraping
- requests==2.31.0
- beautifulsoup4==4.12.0
- playwright==1.41.2 (gestion du contenu dynamique)

### Base de donnÃ©es
- pymongo==4.6.0
- MongoDB

## 7ï¸âƒ£ Justification des choix techniques
### ğŸ”¹ Pourquoi MongoDB ?
Les donnÃ©es scrapÃ©es sont semi-structurÃ©es et susceptibles dâ€™Ã©voluer.
MongoDB permet :
- une flexibilitÃ© de schÃ©ma
- une intÃ©gration simple avec Python
- un stockage adaptÃ© aux documents JSON

### ğŸ”¹ Pourquoi Playwright ?
VidIQ utilise du JavaScript pour gÃ©nÃ©rer dynamiquement le contenu.
Playwright permet :
- le rendu complet de la page
- lâ€™automatisation dâ€™un navigateur rÃ©el
- un scraping plus robuste

### ğŸ”¹ Pourquoi Docker ?
Docker garantit :
- la reproductibilitÃ© de lâ€™environnement
- lâ€™isolation des services
- un dÃ©ploiement simplifiÃ©
- le respect des exigences du projet

## 8ï¸âƒ£ Installation & Lancement
### PrÃ©requis
- Docker
- Docker Compose

âš ï¸ Le projet est conÃ§u pour Ãªtre exÃ©cutÃ© uniquement via Docker.

### DÃ©marrage rapide
1. Construire et lancer les services :
   ```bash
   docker-compose up --build
   ```
2. AccÃ©der Ã  lâ€™application :
   Ouvrir dans un navigateur :
   [http://localhost:8000](http://localhost:8000)
3. ArrÃªter les services :
   ```bash
   docker-compose down
   ```

## 9ï¸âƒ£ FonctionnalitÃ©s principales
- Affichage du Top 100 mondial
- Consultation des statistiques individuelles
- DonnÃ©es stockÃ©es et persistÃ©es en base
- Architecture modulaire (scrapers sÃ©parÃ©s de lâ€™app)

## ğŸ“„ Documentation technique
Le projet repose sur :
- Une architecture modulaire
- Une sÃ©paration claire entre scraping, stockage et visualisation
- Une conteneurisation complÃ¨te via Docker Compose
- Une base de donnÃ©es persistante

## ğŸ‘©â€ğŸ’» Auteurs
Marie BouÃ«tel
Ghita Bensaleh

ESIEE Paris â€” 2026
Projet Data Engineering